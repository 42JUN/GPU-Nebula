# GPU-Nebula: Intelligent AI GPU Interconnect Control Plane

## Project Overview
GPU-Nebula is a comprehensive web application designed to manage distributed AI GPU clusters. It provides real-time monitoring, intelligent workload scheduling, and dynamic network topology visualization for efficient resource utilization and optimized AI workload placement.

## Features
- **Real-time GPU Monitoring:** Live metrics (utilization, temperature, power, memory) for all GPUs.
- **Intelligent Workload Scheduling:** Topology-aware job placement for optimal performance.
- **Dynamic Network Topology:** Visualization and management of GPU interconnects (NVLink, PCIe, InfiniBand).
- **Fault Detection & Reallocation:** Automatic detection of GPU faults and reallocation of affected workloads.
- **Distributed Agent System:** Lightweight agents for GPU discovery and metric collection on remote machines.
- **User Authentication:** Secure access to the control plane.
- **Scalable Architecture:** Built with FastAPI, React, PostgreSQL, and Docker for production readiness.

## Technologies
- **Backend:** Python 3.9+, FastAPI, SQLAlchemy, PostgreSQL, Redis, Uvicorn
- **Frontend:** React 18, TypeScript, Material-UI (or Tailwind CSS), React Query, WebSockets
- **Deployment:** Docker, Docker Compose

## Setup Instructions

### Prerequisites
- Docker Desktop (or Docker Engine and Docker Compose) installed on your system.

### 1. Clone the Repository
```bash
git clone https://github.com/your-username/GPU-Nebula.git
cd GPU-Nebula
```

### 2. Build and Run with Docker Compose
Navigate to the root directory of the project (where `docker-compose.yml` is located) and run:

```bash
docker-compose up --build -d
```
This command will:
- Build the Docker images for the backend and frontend.
- Start the PostgreSQL database, Redis, backend API, and frontend Nginx services.
- The `-d` flag runs the services in detached mode (in the background).

### 3. Access the Application

- **Frontend:** Open your web browser and go to `http://localhost:3000`
- **Backend API Documentation (Swagger UI):** Access the interactive API documentation at `http://localhost:8000/docs`
- **Backend API Redoc:** Access the Redoc API documentation at `http://localhost:8000/redoc`

### 4. Stopping the Application
To stop all running services, run the following command in the project root directory:

```bash
docker-compose down
```
To stop and remove all containers, networks, and volumes created by `up`, use:
```bash
docker-compose down --volumes
```

## Development

### Backend
- The backend code is located in the `backend/` directory.
- Changes to backend files will trigger a reload of the `backend` service due to the `--reload` flag in `docker-compose.yml`.

### Frontend
- The frontend code is located in the `frontend/` directory.
- For frontend development, you might want to run the React development server directly:
  ```bash
  cd frontend
  npm install # or yarn install
  npm start # or yarn start
  ```
  If you run the frontend development server directly, ensure your backend is running (e.g., via `docker-compose up backend db redis -d`) and configure your React app to proxy API requests to `http://localhost:8000`.

## API Endpoints
The backend API documentation is automatically generated by FastAPI and available at `http://localhost:8000/docs`.

## Contributing
(Placeholder for contribution guidelines)

## License
(Placeholder for license information)
